<!--
Google IO 2012 HTML5 Slide Template

Authors: Eric Bidelman <ebidel@gmail.com>
         Luke Mah√© <lukem@google.com>

URL: https://code.google.com/p/io-2012-slides
-->
<!DOCTYPE html>
<html>
<head>
  <title>BB Session</title>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="chrome=1">
  <!--<meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">-->
  <!--<meta name="viewport" content="width=device-width, initial-scale=1.0">-->
  <!--This one seems to work all the time, but really small on ipad-->
  <!--<meta name="viewport" content="initial-scale=0.4">-->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <link rel="stylesheet" media="all" href="theme/css/default.css">
  <link rel="stylesheet" media="only screen and (max-device-width: 480px)" href="theme/css/phone.css">
  <base target="_blank"> <!-- This amazingness opens all links in a new tab. -->
  <script data-main="js/slides" src="js/require-1.0.8.min.js"></script>
</head>
<body style="opacity: 0">

<slides class="layout-widescreen">

    <slide class="title-slide segue nobackground">
        <!-- The content of this hgroup is replaced programmatically through the slide_config.json. -->
        <hgroup class="auto-fadein">
          <h1 data-config-title><!-- populated from slide_config.json --></h1>
          <h2 data-config-subtitle><!-- populated from slide_config.json --></h2>
          <p data-config-presenter><!-- populated from slide_config.json --></p>
        </hgroup>
    </slide>

   <slide class="segue dark quote nobackground">
    <article class="flexbox vleft auto-fadein smaller">
      <q>
        First make your code right, and then make it fast.
      </q>	
      <div class="author">
        Brian Goetz<br>
        Java Concurrency in Practice
      </div>
    </article>
  </slide>

   <slide class="segue dark quote nobackground">
    <article class="flexbox vleft auto-fadein smaller">
      <q>
        Even if you know exactly what is going on in your system, measure performance, don't speculate. You'll learn something, and nine times out of ten, it won't be that you were right!
      </q>	
      <div class="author">
        Ron Jeffries<br>
        Refactoring: Improving the Design of Existing Code
      </div>
    </article>
  </slide>


  <slide>
    <hgroup>
      <h2>Micro-benchmarking</h2>
      <h3>What is it?</h3>	
    </hgroup>
    <aside class="note">
      <section>
        <ul>
          <li>Mencionar diferencias entre micro-benchmark y profiling</li>
          <li>Herramientas para profiling</li>
        </ul>
      </section>
    </aside>
    <article>
      <ul>
        <li>A microbenchmark attempts to measure the performance of a "small" bit of code</li>
	    <li>Micro-benchmarking != Profiling</li>
      </ul>	  	
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Micro-benchmarking</h2>
      <h3>A naive approach</h3>
    </hgroup>
    <article>
      <pre class="prettyprint" data-lang="java">
public void doBenchmark() {
	<b>long initialTime = System.currentTimeMillis();
	codeToTest();
	long finalTime = System.currentTimeMillis();
	long runTime = finalTime - initialTime;</b>
}
	</pre>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Challenges in Micro-benchmarking</h2>
    </hgroup>
    <article>
      <ul class="build">
        <li>Java, interpreted or compiled?
	<ul class="build"> <li>Neither and both at the same time!</li></ul>
	</li>
	<li>Java uses dynamic compilation</li>
	<li>That makes micro-benchmarking far from trivial</li>
      </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Dynamic compilation</h2>
      <h3>A brief history</h3>
    </hgroup>
    <aside class="note">
      <section>
        <ul>
          <li>Mencionar javac y los .class (bytecode)</li>
        </ul>
      </section>
    </aside>
    <article>
	<ul>
        <li>The Java compiler transforms source code into JVM portable bytecode
	<ul><li>Like "virtual machine instructions" for the JVM</li></ul></li>
	<li>How do those bytecodes run on an actual machine?</li>
      </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Dynamic compilation</h2>
      <h3>A brief history</h3>
    </hgroup>
    <aside class="note">
      <section>
        <ul>
          <li>Primeras JVMs como pruebas de concepto</li>
          <li>La performance de Java ahora esta a la par (o mejor) de cualquier otro lenguaje compilado</li>
        </ul>
      </section>
    </aside>
    <article>
	<ul>
        <li>The first JVM implementations (1995) were entirely interpreted
	<ul><li>Ever heard "Java is slower than..."?</li></ul></li>
	<li>Then Just in Time (JIT) compilers came along</li>
      </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>JIT compiler</h2>
    </hgroup>
    <article class="flexbox vcenter">
	<ul>
            <li>Transforms bytecode to machine code in a lazy fashion</li>
	    <li>It only compiles a code path when it knows that code path is about to be executed
	    <ul><li>Hence the name...</li></ul></li>
	    <li>Considerable improvement over fully interpreted</li>
	    <li>However, the optimizations made by the JIT compiler were mediocre</li>
	    <li>To solve this, Java 1.3 introduced HotSpot (actually Java 1.2 but only as an add-on)</li>			
        </ul>
        <img src="images/300px-JITcompilation.jpg" alt="Description" title="Description">
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>HotSpot</h2>
      <h3>What is it?</h3>
    </hgroup>
    <aside class="note">
      <section>
        <ul>
          <li>Client comienza mas rapido pero aplica menos optimizaciones. Ideal para GUIs pq hay poca variabilidad</li>
          <li>Server tiene un start-up mas lento pero a la larga tiene mejor performance. Ideal para procesos largos</li>
          <li>Primera version de HotSpot en 1999</li>
        </ul>
      </section>
    </aside>
    <article class="vcenter">
	    <ul>
            <li><a href="http://en.wikipedia.org/wiki/List_of_Java_virtual_machines">Primary reference Java VM implementation</a></li>
            <li>Has client and server mode</li>
            <li>Combines interpretation, dynamic compilation and profiling</li>
	        <li>Doesn't compile all bytecode to machine code before execution</li>
	        <li>It starts in interpreted mode while collecting profiling data</li>
	        <li>It then compiles only the "hot" code (the code executed most frequently)
	        <ul><li>It doesn't waste time compiling code that is run infrequently</li>
	        <li>That means it has more time to apply optimizations to code that is actually worth it</li>
	        </ul></li>
        </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>HotSpot</h2>
      <h3>Continuous recompilation</h3>
    </hgroup>
    <article>
	<ul>
        <li>Compilation is not an "all or nothing" deal</li>
	<li>A compiled code can be recompiled several times to apply further optimizations</li>
	<li>It can even be de-compiled</li>
	<li>You can use the "-XX:+PrintCompilation" flag to see some interesting logs</li>
      </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>What about micro-benchmarking</h2>
    </hgroup>
    <article>
	<ul>
	<li>Benchmarking in static compiled languages like C is reasonably easy</li>
	<li>Just look at the compiled machine code</li>
        <li>Writing and interpreting benchmarks in Java is almost impossible without knowing the basics of dynamic compilation
	<ul><li>Even then is pretty hard!</li></ul></li>
      </ul>
    </article>
  </slide>

<slide>
    <hgroup>
      <h2>HotSpot</h2>
      <h3>Dead code elimination</h3>
    </hgroup>
    <article>
      <ul><li>The compiler can detect and remove dead code (code that has no effect on the outcome)</li></ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Dead code elimination</h2>
      <h3>An example</h3>
    </hgroup>
    <article>
      <ul><li>How much does this code take to run?</li></ul>	
      <pre class="prettyprint" data-lang="java">
private final int[] array = new int[1000000];

public void timeArrayIteration_BAD() {
   <b>for (int ignoreMe : array) {}</b>
}
	</pre>
	<ul class="build">
	   <li>1 ns in my laptop</li>
	   <li>Wait... what? 1 ns to iterate over a million elements?</li>
	</ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Java micro-benchmarking</h2>
      <h3>Challenges</h3>	
    </hgroup>
    <article>
	<ul>
	<li>The code can be dynamically compiled and decompiled several times</li>
	<li>The results are dependent on the hardware, OS and even JVM used</li>
	<li>GC can start running in the middle of your benchmark</li>
	<li>The compiler can decide to optimize away parts of your code</li>
	<li>The list goes on and on...</li>
      </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Java micro-benchmarking</h2>
      <h3>When should you do it?</h3>	
    </hgroup>
    <article>
	<ul>
	<li>Most of the time, you shouldn't</li>
	<li>Stick to clear code and good designs</li>
	<li>The compiler does a better job at optimizing code than you anyways...</li>
      </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>"Clever" optimization</h2>
      <h3>Epic fail</h3>
    </hgroup>
    <aside class="note">
      <section>
        <ul>
          <li>Que pasa si climb() tira un ArrayIndex...Exception()?</li>
        </ul>
      </section>
    </aside>
    <article class="smaller build">
        <pre class="prettyprint" data-lang="java">
for (int i=0; i < range.length; i++)
    range[i].climb();
	</pre>
      <pre class="prettyprint" data-lang="java">
try {
    int i = 0;
    while(true)
        range[i++].climb();
} catch(ArrayIndexOutOfBoundsException e) {}
	</pre>
      
	<ul class="build">
	   <li>Reasoning: "The loop termination test must be really expensive"</li>
	   <li>Performance aside, which one is clearer?</li>
	   <li>The "optimized" version runs several times slower than the "non-optimized" version on any modern JVM</li>
	</ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Java micro-benchmarking</h2>
      <h3>How should you do it?</h3>	
    </hgroup>
    <article>
	<ul>
	<li>There are cases where micro-benchmarking can be useful
	<ul>
	    <li>"Should I use Implementation A or B of this algorithm?"</li>
	    <li>"Is this code optimization really worth the simplicity it sacrifices"?</li>
	    <li>"Does the latest JRE make this piece of code faster than previous versions"?</li>
        <li>Plain fun: "My Java is faster than your..."</li>
	</ul></li>
	<li>Don't try to reinvent the wheel while writing micro-benchmarks</li>
	<li>Someone has already done it!</li>
      </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Caliper</h2>
    </hgroup>
    <article>
	<ul>
	<li>Google's open-source framework for writing, running and viewing the results of Java micro-benchmarks</li>
	<li>It takes care of most of the challenges involved for you</li>
	<li>It follows a convention similar to Junit 3</li>
      </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Caliper</h2>
      <h3>Structure of a benchmark</h3>
    </hgroup>
    <article class="smaller">
      <pre class="prettyprint" data-lang="java">
public class MyBenchmark extends SimpleBenchmark {
@Override
protected void setUp() throws Exception {
    super.setUp();
}
@Override
protected void tearDown() throws Exception {
    super.tearDown();
}
public void timeMyOperation(int reps) {
    for (int i = 0; i < reps; i++) {
      MyClass.myOperation();
    }
  }
}
	</pre>
	<ul>
	   <li>All benchmark classes extend <a href="http://caliper.googlecode.com/svn/static/api/reference/com/google/caliper/SimpleBenchmark.html">SimpleBechmark</a></li>
	   <li>Every benchmark method must begin with "time..." and have a "int reps" parameter</li>
	   <li>There is "setup" and "tearDown" methods for init and cleanup tasks</li>
	</ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Caliper</h2>
      <h3>How it works</h3>
    </hgroup>
    <article>
	<ul>
	<li>A new JVM process is spawned for every run</li>
	<li>The framework takes care of warming up the JVM</li>
	<li>The benchmark code is run until the measured values converge within a specified threshold</li>
	<li>The measured values are statistically analyzed to remove outliers caused by GC or dynamic compilation</li>
      </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Caliper</h2>
      <h3>Benefits of using it</h3>
    </hgroup>
    <article>
	<ul>
	<li>It automatically deals with all the challenges of dynamic compilation and GC</li>
	<li>It detects when your code is being optimized away (dead code)</li>
	<li>It usually measures execution time but it can also calculate other metrics
	<ul>
	    <li>CPU time</li>
	    <li>Memory allocation</li>
	    <li>Contention</li>
	</ul></li>
	<li>It's really easy to use and extend</li>
	<li>It's highly customizable</li>
      </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Conclusions</h2>
    </hgroup>
    <aside class="note">
      <section>
        <ul>
          <li>Dont desing for performance se refiere a codigo. Siempre hay que considerar como la arquitectura va a impactar performance desde un principio</li>
          <li>Hacer micro-benchmarks esta relacionado a aplicar el metodo cientifico</li>
        </ul>
      </section>
    </aside>
    <article>
	<ul>
	<li>Don't desing for performance. Write clear and easy to understand code</li>
	<li>Don't try to outsmart the compiler. It will backfire 99% of the time</li>
	<li>Java code is particularly hard to micro-benchmark. Next time someone says "X is faster than Y", be skeptical</li>
	<li>Micro-benchmarks results are unreliable. Use profiling on a real environment if possible</li>
    <li>If you still feel you should micro-benchmark some code, use Caliper or a similar library. Even then, analyze the results and use your common sense</li>
    </ul>
    </article>
  </slide>

  <slide>
    <hgroup>
      <h2>Links</h2>
    </hgroup>
    <article>
	<ul>
	<li><a href="http://code.google.com/p/caliper/">Caliiper main page</a></li>
    <li><a href="http://code.google.com/p/dalvik/source/browse/trunk/benchmarks/">Dalvik benchmarks</a> An extensive collection of benchmarks for android core libraries</li>
    <li><a href="http://www.ibm.com/developerworks/java/library/j-jtp12214/">Brian Goetz article</a> introducing Java dynamic compilation and HotSpot</li>
   </ul>
    </article>
  </slide>

  <slide class="thank-you-slide segue nobackground">
    <article class="flexbox vleft auto-fadein">
      <h2>&lt;Thank You!&gt;</h2>
    </article>
    <p class="auto-fadein" data-config-contact>
      <!-- populated from slide_config.json -->
    </p>
  </slide>
  <slide class="backdrop"></slide>

</slides>

<script>
var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-XXXXXXXX-1']);
_gaq.push(['_trackPageview']);

(function() {
  var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
  ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
  var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})();
</script>

<!--[if IE]>
  <script src="http://ajax.googleapis.com/ajax/libs/chrome-frame/1/CFInstall.min.js"></script>
  <script>CFInstall.check({mode: 'overlay'});</script>
<![endif]-->
</body>
</html>
